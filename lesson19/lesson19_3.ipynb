{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20d0ccd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料夾絕對路徑:\n",
      "C:\\Users\\bondy\\OneDrive\\文件\\Github\\bondsyang_0625\\lesson19\\每日各站進出站人數\n",
      "\n",
      "檔案絕對路徑 (已排除 manifest.csv, schema.csv):\n",
      "['C:\\\\Users\\\\bondy\\\\OneDrive\\\\文件\\\\Github\\\\bondsyang_0625\\\\lesson19\\\\每日各站進出站人數\\\\每日各站進出站人數20190423-20191231.csv', 'C:\\\\Users\\\\bondy\\\\OneDrive\\\\文件\\\\Github\\\\bondsyang_0625\\\\lesson19\\\\每日各站進出站人數\\\\每日各站進出站人數2020.csv', 'C:\\\\Users\\\\bondy\\\\OneDrive\\\\文件\\\\Github\\\\bondsyang_0625\\\\lesson19\\\\每日各站進出站人數\\\\每日各站進出站人數2021.csv', 'C:\\\\Users\\\\bondy\\\\OneDrive\\\\文件\\\\Github\\\\bondsyang_0625\\\\lesson19\\\\每日各站進出站人數\\\\每日各站進出站人數2022.csv', 'C:\\\\Users\\\\bondy\\\\OneDrive\\\\文件\\\\Github\\\\bondsyang_0625\\\\lesson19\\\\每日各站進出站人數\\\\每日各站進出站人數2023.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "def list_daily_flow_files(base_dir: Path | None = None):\n",
    "    \"\"\"\n",
    "    1. 取得 '每日各站進出站人數' 資料夾\n",
    "    2. 取得其中所有 CSV 檔案的絕對路徑\n",
    "    3. 排除 manifest.csv 與 schema.csv\n",
    "    \"\"\"\n",
    "    if base_dir is None:\n",
    "        base_dir = Path.cwd()  # 與 lesson19_2.ipynb 做法一致\n",
    "    target_dir = base_dir / \"每日各站進出站人數\"\n",
    "    if not target_dir.is_dir():\n",
    "        raise FileNotFoundError(f\"找不到資料夾: {target_dir}\")\n",
    "\n",
    "    excluded = {\"manifest.csv\", \"schema.csv\"}\n",
    "    csv_paths = sorted(\n",
    "        p.resolve()\n",
    "        for p in target_dir.glob(\"*.csv\")\n",
    "        if p.name not in excluded\n",
    "    )\n",
    "    return target_dir.resolve(), csv_paths\n",
    "\n",
    "folder_abs_path, file_abs_paths = list_daily_flow_files()\n",
    "\n",
    "print(\"資料夾絕對路徑:\")\n",
    "print(folder_abs_path)\n",
    "print(\"\\n檔案絕對路徑 (已排除 manifest.csv, schema.csv):\")\n",
    "file_abs_paths = [str(p) for p in file_abs_paths]\n",
    "print(file_abs_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc56dd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>車站代碼</th>\n",
       "      <th>車站名稱</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900</td>\n",
       "      <td>基隆</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>910</td>\n",
       "      <td>三坑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>八堵</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930</td>\n",
       "      <td>七堵</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>940</td>\n",
       "      <td>百福</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>7360</td>\n",
       "      <td>瑞芳</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>7361</td>\n",
       "      <td>海科館</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>7362</td>\n",
       "      <td>八斗子</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>7380</td>\n",
       "      <td>四腳亭</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>7390</td>\n",
       "      <td>暖暖</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     車站代碼 車站名稱\n",
       "0     900   基隆\n",
       "1     910   三坑\n",
       "2     920   八堵\n",
       "3     930   七堵\n",
       "4     940   百福\n",
       "..    ...  ...\n",
       "238  7360   瑞芳\n",
       "239  7361  海科館\n",
       "240  7362  八斗子\n",
       "241  7380  四腳亭\n",
       "242  7390   暖暖\n",
       "\n",
       "[243 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "current_dir = Path.cwd()\n",
    "# 若 CSV 與此 notebook 同資料夾\n",
    "csv_path = current_dir / \"台鐵車站資訊.csv\"\n",
    "stations_df = pd.read_csv(csv_path)\n",
    "#display(stations_df.head())\n",
    "stations_df = stations_df.reindex(columns=[\"stationCode\", \"stationName\"])\n",
    "\n",
    "#欄位名稱更改為[車站代碼, 車站名稱]\n",
    "stations_df.columns = [\"車站代碼\", \"車站名稱\"]\n",
    "stations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03323b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>車站名稱</th>\n",
       "      <th>進站人數</th>\n",
       "      <th>出站人數</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>日期</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-23</th>\n",
       "      <td>基隆</td>\n",
       "      <td>8442</td>\n",
       "      <td>7743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-23</th>\n",
       "      <td>三坑</td>\n",
       "      <td>1394</td>\n",
       "      <td>1348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-23</th>\n",
       "      <td>八堵</td>\n",
       "      <td>2770</td>\n",
       "      <td>2423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-23</th>\n",
       "      <td>七堵</td>\n",
       "      <td>6113</td>\n",
       "      <td>6335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-23</th>\n",
       "      <td>百福</td>\n",
       "      <td>2680</td>\n",
       "      <td>2726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>瑞芳</td>\n",
       "      <td>7916</td>\n",
       "      <td>8252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>海科館</td>\n",
       "      <td>164</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>八斗子</td>\n",
       "      <td>652</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>四腳亭</td>\n",
       "      <td>1526</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>暖暖</td>\n",
       "      <td>576</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406761 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           車站名稱  進站人數  出站人數\n",
       "日期                         \n",
       "2019-04-23   基隆  8442  7743\n",
       "2019-04-23   三坑  1394  1348\n",
       "2019-04-23   八堵  2770  2423\n",
       "2019-04-23   七堵  6113  6335\n",
       "2019-04-23   百福  2680  2726\n",
       "...         ...   ...   ...\n",
       "2023-12-31   瑞芳  7916  8252\n",
       "2023-12-31  海科館   164   195\n",
       "2023-12-31  八斗子   652   720\n",
       "2023-12-31  四腳亭  1526   656\n",
       "2023-12-31   暖暖   576   447\n",
       "\n",
       "[406761 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#建立一個function\n",
    "#要concate下面迴圈的所有merged_df\n",
    "def process_yearly_data(file_abs_paths, stations_df):\n",
    "    merged_dfs = []\n",
    "    for csv_path in file_abs_paths:\n",
    "        year_df = pd.read_csv(csv_path)\n",
    "        year_df.columns = [\"日期\", \"車站代碼\", \"進站人數\", \"出站人數\"]\n",
    "        #display(year_df.head())\n",
    "        #日期欄位目前是int64, 需要轉換為datetime格式\n",
    "        year_df[\"日期\"] = pd.to_datetime(year_df[\"日期\"], format=\"%Y%m%d\")\n",
    "        merged_df = pd.merge(year_df, stations_df, on=\"車站代碼\")\n",
    "        merged_df = merged_df.reindex(columns=[\"日期\",\"車站名稱\",\"進站人數\",\"出站人數\"])\n",
    "        merged_df.head()\n",
    "        #將欄位:日期,變為index\n",
    "        merged_df.set_index(\"日期\", inplace=True)\n",
    "        merged_dfs.append(merged_df)\n",
    "    return pd.concat(merged_dfs)\n",
    "result_df = process_yearly_data(file_abs_paths, stations_df)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c46d05",
   "metadata": {},
   "source": [
    "以下針對所選儲存格的程式碼說明，分段以繁體中文敘述重點與注意事項。\n",
    "\n",
    "此函式的目的與輸入  \n",
    "process_yearly_data 定義了一個將多個年度 CSV 檔合併成單一 Pandas DataFrame 的流程。它接受兩個參數：file_abs_paths（可迭代的 CSV 路徑清單）與 stations_df（包含車站代碼與車站名稱的 DataFrame，用於後續合併）。呼叫後會回傳一個以「日期」為索引、欄位包含車站名稱與進出站人數的合併表。\n",
    "\n",
    "每個檔案的處理步驟（逐行重點）  \n",
    "在迴圈中對每個 csv_path 執行 pd.read_csv 讀取資料，隨即用 year_df.columns 直接覆寫欄位名稱為 [\"日期\",\"車站代碼\",\"進站人數\",\"出站人數\"]（這假定每個 CSV 欄位順序一致且數目正確）。接著把原本以數字或字串表示的日期轉為 datetime（format=\"%Y%m%d\"），確保日期欄位成為 datetime64 類型以利時間序列操作。然後以 pd.merge 將 year_df 與傳入的 stations_df 依「車站代碼」合併，並用 reindex 選取與排列所需欄位。最後把「日期」設為 index（inplace=True），將每個處理後的 DataFrame 推入 merged_dfs 列表。\n",
    "\n",
    "回傳結果與在 Notebook 的顯示行為  \n",
    "函式最終以 pd.concat 將 merged_dfs 中所有年份的 DataFrame 縱向合併並回傳。呼叫端把回傳值指定給 result_df，並在儲存格最後單寫 result_df，這在 Jupyter Notebook 會觸發 notebook 自動顯示該 DataFrame 的摘要（等同 display(result_df)）。\n",
    "\n",
    "常見陷阱（gotchas）  \n",
    "- 如果 file_abs_paths 為空清單，pd.concat(merged_dfs) 會拋出 ValueError（\"No objects to concatenate\"）。  \n",
    "- 直接用 year_df.columns 覆寫欄位會在原始 CSV 欄位數不符或順序不同時導致錯誤或錯置欄位。  \n",
    "- pd.merge 需要 stations_df 含有精確對應的「車站代碼」欄位，否則會產生缺值或資料遺漏。  \n",
    "- 合併後可能出現相同日期與車站的重複列（若不同檔案含同日資料），pd.concat 不會自動合併或聚合重複列。  \n",
    "- 若資料量大，將所有年度讀入記憶體並 concat 會消耗大量記憶體與時間。\n",
    "\n",
    "改進建議（可快速降低錯誤與提升效能）  \n",
    "- 防護空清單：在回傳時處理 merged_dfs 為空的情況。  \n",
    "- 在 read_csv 使用 parse_dates 與 usecols，以避免額外的 pd.to_datetime 與減少讀入欄位數量。  \n",
    "- 合併後若需要時間序列順序，呼叫 sort_index()；若需處理重複，可 groupby 並 aggregate（例如 sum）。  \n",
    "- 驗證每個 CSV 欄位數與 stations_df 是否包含預期欄位，或使用 try/except 做錯誤紀錄與跳過。\n",
    "\n",
    "範例修正片段（處理空清單、排序、以及使用 parse_dates）：  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c278b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例修正（替換原回傳與讀檔方式）\n",
    "def process_yearly_data(file_abs_paths, stations_df):\n",
    "    merged_dfs = []\n",
    "    for csv_path in file_abs_paths:\n",
    "        # 範例：只讀必要欄位並直接解析日期\n",
    "        year_df = pd.read_csv(csv_path, usecols=[0,1,2,3], parse_dates=[0], dtype={1: str})\n",
    "        year_df.columns = [\"日期\", \"車站代碼\", \"進站人數\", \"出站人數\"]\n",
    "        merged_df = pd.merge(year_df, stations_df, on=\"車站代碼\", how=\"left\")\n",
    "        merged_df = merged_df.reindex(columns=[\"日期\",\"車站名稱\",\"進站人數\",\"出站人數\"])\n",
    "        merged_df.set_index(\"日期\", inplace=True)\n",
    "        merged_dfs.append(merged_df)\n",
    "    if not merged_dfs:\n",
    "        return pd.DataFrame(columns=[\"車站名稱\",\"進站人數\",\"出站人數\"])\n",
    "    result = pd.concat(merged_dfs)\n",
    "    result.sort_index(inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a297b09a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "如需，我可以把上述改進整合成完整的儲存格範例、或再加入錯誤紀錄與重複聚合的範例。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dfa719",
   "metadata": {},
   "source": [
    "以下為該儲存格（兩行程式碼）的逐段說明，重點放在行為、回傳結果與可能的陷阱，語言為繁體中文。\n",
    "\n",
    "- 第一段（result_df = process_yearly_data(file_abs_paths, stations_df））  \n",
    "  這一行呼叫先前定義的函式 process_yearly_data，並把兩個參數傳入：file_abs_paths（多個 CSV 檔案的路徑清單）與 stations_df（包含車站代碼與車站名稱的 DataFrame）。函式會逐一讀取每個 CSV、重新命名欄位、將「日期」欄轉為 datetime、以「車站代碼」與 stations_df 做合併、把「日期」設為索引，然後把每個檔案產生的 DataFrame 收集到列表中，最後以 pd.concat 將所有年度資料縱向合併回傳。執行結果被指派給變數 result_df，因此此變數會持有整合後的 Pandas DataFrame。\n",
    "\n",
    "- 第二段（result_df）在 Jupyter Notebook 的語意與效果  \n",
    "  單獨把變數名稱放在儲存格最後一行，是 Jupyter Notebook 的顯示約定：Notebook 會把該變數的代表值渲染在輸出區（通常等同於 display(result_df)）。因此使用者會在輸出窗格看到整合後的表格摘要（head、索引類型、欄位、資料型別等）。在一般的 Python 腳本中，僅寫變數名稱不會顯示內容，需明確呼叫 print() 或 display()。\n",
    "\n",
    "- result_df 的資料結構與內容  \n",
    "  根據 process_yearly_data 的實作，回傳的 DataFrame 會以「日期」欄位（已轉為 datetime）作為索引（DatetimeIndex），主要欄位依序為「車站名稱」、「進站人數」、「出站人數」。每一列代表某一日期、某一車站的進出站數；不同 CSV（不同年度）讀入後的列會被縱向堆疊在一起。資料型別重點：日期為 datetime64[ns]（作為索引），人數欄位通常為整數或浮點（取決於 CSV 原始格式）。\n",
    "\n",
    "- 常見的 gotchas 與改進建議  \n",
    "  - 若 file_abs_paths 是空清單，pd.concat(merged_dfs) 會丟出 ValueError（因為沒有物件可 concat）；可改為在函式最後改成 return pd.concat(merged_dfs) if merged_dfs else pd.DataFrame()。  \n",
    "  - pd.concat 並不自動排序或移除重複索引；若希望依日期排序或處理重複（同一車站同日重複來源），可在 concat 後呼叫 result_df.sort_index() 或使用 groupby/agg 做合併規則。  \n",
    "  - 合併時 stations_df 必須包含「車站代碼」欄位且名稱精準對應，否則 pd.merge 會產生空值或找不到對應行。  \n",
    "  - 讀多個大型 CSV 會耗記憶體；若資料量大，考慮逐塊處理或使用 dask、分批寫入磁碟。  \n",
    "  - 檔案處理順序會影響最終 row 的排列；若需要時間序列一致性，最好在 concat 後排序或先對 file_abs_paths 做明確排序。\n",
    "\n",
    "如需我把上述說明改寫成註解加入原程式或提供處理空清單、排序、或去重的具體範例，請告訴我想放在哪個檔案或儲存格。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis_1_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
